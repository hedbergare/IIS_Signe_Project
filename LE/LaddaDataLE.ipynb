{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nödvändiga importer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from imageio import v3 as iio\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "from ladda_data import prepare_all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    'letter_A',\n",
    "    'letter_B',\n",
    "    'letter_C',\n",
    "    'letter_L',\n",
    "    'letter_R',\n",
    "    'letter_U'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_letter(letter):\n",
    "    data_all_videos = []\n",
    "    path = f'../dataset_v0/ASL_{letter}'\n",
    "    CSV = pd.read_csv(f'{path}/annotations.csv')\n",
    "    num_of_videos = CSV['video_idx'].nunique()\n",
    "    for video_index in range(num_of_videos):\n",
    "        one_video = iio.imread(f'{path}/videos/video_{video_index}.mp4')\n",
    "        if video_index == 7:\n",
    "            print(one_video.shape)\n",
    "        if one_video.shape[1] == 480 or one_video.shape[2] == 640:\n",
    "            print(video_index, ' av ' ,num_of_videos )\n",
    "            one_video = iio.imread(f'{path}/videos/video_{video_index}.mp4')\n",
    "            one_video_csv = CSV[CSV['video_idx']==video_index]\n",
    "            pairs_from_one_video = get_one_video(one_video_csv,one_video)\n",
    "            data_all_videos.extend(pairs_from_one_video)\n",
    "    return shuffle_and_split(data_all_videos)\n",
    "\n",
    "        \n",
    "def shuffle_and_split(letter_data):\n",
    "    random.shuffle(letter_data)\n",
    "    train_size = round(0.8 * len(letter_data))\n",
    "    train_set = letter_data[0:train_size]\n",
    "    test_set = letter_data[train_size:len(letter_data)]\n",
    "    return train_set, test_set\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_one_video(one_video_csv,one_video):\n",
    "    x_y_pairs = []\n",
    "    num_of_frames = one_video_csv['frame'].nunique()\n",
    "    for frame_index in range(num_of_frames-1):\n",
    "        one_frame_csv = one_video_csv[one_video_csv['frame']==frame_index]\n",
    "        one_frame_csv = one_frame_csv[one_frame_csv['joint']!='hand_position']\n",
    "        this_frame = one_video[frame_index]\n",
    "        this_frame_tensor = torch.tensor(this_frame)\n",
    "        this_frame_tensor = torch.reshape(this_frame_tensor,(3,640,480))\n",
    "        csv_one_frame = get_data_from_one_frame(one_frame_csv)\n",
    "        x_y_pairs.append([this_frame_tensor, csv_one_frame])\n",
    "    return x_y_pairs\n",
    "\n",
    "\n",
    "\n",
    "def get_data_from_one_frame(one_frame_csv):\n",
    "    cord_list = []\n",
    "    for index, row in one_frame_csv.iterrows():\n",
    "        cord_list.append(row['x'])\n",
    "        cord_list.append(row['y'])\n",
    "    cord_tensor = torch.tensor(cord_list)\n",
    "    return cord_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter_A\n",
      "0  av  35\n",
      "1  av  35\n",
      "2  av  35\n",
      "3  av  35\n",
      "4  av  35\n",
      "5  av  35\n",
      "6  av  35\n",
      "(225, 720, 1280, 3)\n",
      "8  av  35\n",
      "9  av  35\n",
      "10  av  35\n",
      "11  av  35\n",
      "12  av  35\n",
      "13  av  35\n",
      "14  av  35\n",
      "15  av  35\n",
      "16  av  35\n",
      "17  av  35\n",
      "18  av  35\n",
      "19  av  35\n",
      "20  av  35\n",
      "21  av  35\n",
      "22  av  35\n",
      "23  av  35\n",
      "24  av  35\n",
      "25  av  35\n",
      "26  av  35\n",
      "27  av  35\n",
      "28  av  35\n",
      "29  av  35\n",
      "30  av  35\n",
      "31  av  35\n",
      "32  av  35\n",
      "33  av  35\n",
      "letter_B\n",
      "0  av  36\n",
      "1  av  36\n",
      "2  av  36\n",
      "3  av  36\n",
      "4  av  36\n",
      "5  av  36\n",
      "6  av  36\n",
      "(258, 480, 640, 3)\n",
      "7  av  36\n",
      "9  av  36\n",
      "10  av  36\n",
      "11  av  36\n",
      "12  av  36\n",
      "13  av  36\n",
      "14  av  36\n",
      "15  av  36\n",
      "16  av  36\n",
      "17  av  36\n",
      "18  av  36\n",
      "19  av  36\n",
      "20  av  36\n",
      "21  av  36\n",
      "22  av  36\n",
      "23  av  36\n",
      "24  av  36\n",
      "25  av  36\n",
      "26  av  36\n",
      "27  av  36\n",
      "28  av  36\n",
      "29  av  36\n",
      "30  av  36\n",
      "31  av  36\n",
      "32  av  36\n",
      "33  av  36\n",
      "34  av  36\n",
      "letter_C\n",
      "0  av  36\n",
      "1  av  36\n",
      "2  av  36\n",
      "3  av  36\n",
      "4  av  36\n",
      "5  av  36\n",
      "6  av  36\n",
      "(222, 480, 640, 3)\n",
      "7  av  36\n",
      "9  av  36\n",
      "10  av  36\n",
      "11  av  36\n",
      "12  av  36\n",
      "13  av  36\n",
      "14  av  36\n",
      "15  av  36\n",
      "16  av  36\n",
      "17  av  36\n",
      "18  av  36\n",
      "19  av  36\n",
      "20  av  36\n",
      "21  av  36\n",
      "22  av  36\n",
      "23  av  36\n",
      "24  av  36\n",
      "25  av  36\n",
      "26  av  36\n",
      "27  av  36\n",
      "28  av  36\n",
      "29  av  36\n",
      "30  av  36\n",
      "31  av  36\n",
      "32  av  36\n",
      "33  av  36\n",
      "34  av  36\n",
      "letter_L\n",
      "0  av  35\n",
      "1  av  35\n",
      "2  av  35\n",
      "3  av  35\n",
      "4  av  35\n",
      "5  av  35\n",
      "6  av  35\n",
      "(210, 720, 1280, 3)\n",
      "8  av  35\n",
      "9  av  35\n",
      "10  av  35\n",
      "11  av  35\n",
      "12  av  35\n",
      "13  av  35\n",
      "14  av  35\n",
      "15  av  35\n",
      "16  av  35\n",
      "17  av  35\n",
      "18  av  35\n",
      "19  av  35\n",
      "20  av  35\n",
      "21  av  35\n",
      "22  av  35\n",
      "23  av  35\n",
      "24  av  35\n",
      "25  av  35\n",
      "26  av  35\n",
      "27  av  35\n",
      "28  av  35\n",
      "29  av  35\n",
      "30  av  35\n",
      "31  av  35\n",
      "32  av  35\n",
      "33  av  35\n",
      "letter_R\n",
      "0  av  36\n",
      "1  av  36\n",
      "2  av  36\n",
      "3  av  36\n",
      "4  av  36\n",
      "5  av  36\n",
      "6  av  36\n",
      "(212, 480, 640, 3)\n",
      "7  av  36\n",
      "9  av  36\n",
      "10  av  36\n",
      "11  av  36\n",
      "12  av  36\n",
      "13  av  36\n",
      "14  av  36\n",
      "15  av  36\n",
      "16  av  36\n",
      "17  av  36\n",
      "18  av  36\n",
      "19  av  36\n",
      "20  av  36\n",
      "21  av  36\n",
      "22  av  36\n",
      "23  av  36\n",
      "24  av  36\n",
      "25  av  36\n",
      "26  av  36\n",
      "27  av  36\n",
      "28  av  36\n",
      "29  av  36\n",
      "30  av  36\n",
      "31  av  36\n",
      "32  av  36\n",
      "33  av  36\n",
      "34  av  36\n",
      "letter_U\n",
      "0  av  36\n",
      "1  av  36\n",
      "2  av  36\n",
      "3  av  36\n",
      "4  av  36\n",
      "5  av  36\n",
      "6  av  36\n",
      "(218, 480, 640, 3)\n",
      "7  av  36\n",
      "9  av  36\n",
      "10  av  36\n",
      "11  av  36\n",
      "12  av  36\n",
      "13  av  36\n",
      "14  av  36\n",
      "15  av  36\n",
      "16  av  36\n",
      "17  av  36\n",
      "18  av  36\n",
      "19  av  36\n",
      "20  av  36\n",
      "21  av  36\n",
      "22  av  36\n",
      "23  av  36\n",
      "24  av  36\n",
      "25  av  36\n",
      "26  av  36\n",
      "27  av  36\n",
      "28  av  36\n",
      "29  av  36\n",
      "30  av  36\n",
      "31  av  36\n",
      "32  av  36\n",
      "33  av  36\n",
      "34  av  36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def write_test(list):\n",
    "    torch.save(list, 'testdata.pt')\n",
    "\n",
    "def write_train(list):\n",
    "    torch.save(list, 'traindata.pt')\n",
    "\n",
    "\n",
    "\n",
    "def data_all_letters(gestures):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for gesture in gestures:\n",
    "        print(gesture)\n",
    "        train_for_gesture, test_for_gesture = get_one_letter(gesture)\n",
    "        train_data.extend(train_for_gesture)\n",
    "        test_data.extend(test_for_gesture)\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(test_data)\n",
    "    write_train(train_data)\n",
    "    write_test(test_data)\n",
    "\n",
    "data_all_letters(gestures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('1')\n",
    "loaded_train = torch.load('traindata.pt')\n",
    "print('2')\n",
    "loaded_test = torch.load('testdata.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = prepare_all_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32572\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
